{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sapRMaAkYCpq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "model_names = ['KNN', 'XGBoost', 'Logistic Regression', 'RandomForest', 'SVM']\n",
        "accuracies_without_smote = [0.7675, 0.8546, 0.3222, 0.8860, 0.8801]\n",
        "accuracies_with_smote = [0.9963, 0.8546, 0.1121, 0.9623, 0.9134]\n",
        "\n",
        "# Settings\n",
        "x = np.arange(len(model_names))\n",
        "bar_width = 0.3\n",
        "fig, ax = plt.subplots(figsize=(7, 5))\n",
        "\n",
        "# Bars\n",
        "bars1 = ax.bar(x - bar_width / 2, accuracies_without_smote, width=bar_width,\n",
        "               label='Without SMOTE', color='steelblue', edgecolor='black')\n",
        "bars2 = ax.bar(x + bar_width / 2, accuracies_with_smote, width=bar_width,\n",
        "               label='With SMOTE', color='orange', edgecolor='black')\n",
        "\n",
        "# Add value labels (always black text)\n",
        "def add_labels(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width() / 2, height + 0.015,\n",
        "                f'{height:.4f}', ha='center', va='bottom',\n",
        "                fontsize=5, color='black', fontweight='bold')\n",
        "\n",
        "add_labels(bars1)\n",
        "add_labels(bars2)\n",
        "\n",
        "# Axes and ticks\n",
        "ax.set_xlabel(\"Models\", fontsize=16, fontweight='bold')\n",
        "ax.set_ylabel(\"Accuracy\", fontsize=16, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(model_names, fontsize=13, rotation=15)\n",
        "ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Legend\n",
        "ax.legend(fontsize=11, loc='lower right', frameon=True)\n",
        "\n",
        "# Layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Models\n",
        "models = ['KNN', 'Random Forest', 'XGBoost', 'Logistic Regression', 'SVM']\n",
        "log_loss_without_smote = [0.0905, 0.0221, 0.0003, 0.4345, 0.6504]\n",
        "log_loss_with_smote = [0.006049, 3.0433e-05, 4.4951e-05, 0.396829, 0.1062]\n",
        "\n",
        "# Setup\n",
        "x = np.linspace(0, 4, 5)  # Reduced spacing between model groups\n",
        "bar_width = 0.25\n",
        "fig, ax = plt.subplots(figsize=(8, 5.5))\n",
        "\n",
        "# Bar plots\n",
        "bars1 = ax.bar(x - bar_width/2, log_loss_without_smote, width=bar_width, label='Without SMOTE',\n",
        "               color='skyblue', edgecolor='black', log=True)\n",
        "bars2 = ax.bar(x + bar_width/2, log_loss_with_smote, width=bar_width, label='With SMOTE',\n",
        "               color='orange', edgecolor='black', log=True)\n",
        "\n",
        "# Add labels above bars\n",
        "def add_labels(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        label_y = height * 1.4 if height < 0.01 else height * 1.08\n",
        "        ax.text(bar.get_x() + bar.get_width() / 2, label_y,\n",
        "                f'{height:.6f}', ha='center', fontsize=6, fontweight='light', color='black')\n",
        "\n",
        "add_labels(bars1)\n",
        "add_labels(bars2)\n",
        "\n",
        "# Axis labels and ticks\n",
        "ax.set_xlabel('Models', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Log Loss (log scale)', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models, fontsize=12, rotation=15)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "ax.grid(axis='y', linestyle='--', alpha=0.7, which='both')\n",
        "\n",
        "# Legend and layout\n",
        "ax.legend(fontsize=12, loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mj_A78J1ZDQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Your data from the screenshot\n",
        "data = {\n",
        "    'Model': ['XGBoost', 'KNN', 'Random Forest', 'SVM (RBF)', 'Logistic Regression'],\n",
        "    'Avg F1 Score': [0.9946, 0.9780, 0.9675, 0.8308, 0.7813],\n",
        "    'Time Taken (s)': [172.79, 7.49, 94.29, 5210.39, 326.36]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Create figure and twin axis\n",
        "fig, ax1 = plt.subplots(figsize=(10,6))\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "# Bar plot for F1 Score\n",
        "colors = sns.color_palette(\"pastel\")\n",
        "bars = sns.barplot(x='Model', y='Avg F1 Score', data=df, ax=ax1, palette=colors)\n",
        "\n",
        "# Line plot for Time Taken\n",
        "line = ax2.plot(df['Model'], df['Time Taken (s)'], color='black', marker='o', linewidth=2, label='Time (s)')\n",
        "\n",
        "# Titles and labels\n",
        "ax1.set_ylabel('Avg F1 Score', fontsize=12)\n",
        "ax2.set_ylabel('Time Taken (s)', fontsize=12)\n",
        "ax1.set_xlabel('Model', fontsize=12)\n",
        "plt.title('Avg F1 Score and Time per Model (with SMOTE)', fontsize=14)\n",
        "\n",
        "# Legends\n",
        "ax2.legend(loc='upper right')\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3sHc_3RNphwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Step 1: Generate sample data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10,\n",
        "                           n_classes=5, weights=[0.1, 0.2, 0.3, 0.25, 0.15],\n",
        "                           random_state=42)\n",
        "\n",
        "# Step 2: Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# Step 3: Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Step 4: Binarize labels\n",
        "n_classes = len(np.unique(y_train))\n",
        "y_test_bin = label_binarize(y_test, classes=np.unique(y_train))\n",
        "\n",
        "# Step 5: Define classifiers\n",
        "models = {\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    \"Linear SVM\": OneVsRestClassifier(LinearSVC(max_iter=10000))\n",
        "}\n",
        "\n",
        "# Step 6: Plot Precision-Recall Curves\n",
        "plt.figure(figsize=(8, 4))  # Reduced size\n",
        "average_precisions = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_score = model.predict_proba(X_test)\n",
        "    else:\n",
        "        y_score = model.decision_function(X_test)\n",
        "\n",
        "    precision = dict()\n",
        "    recall = dict()\n",
        "    ap_score = []\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])\n",
        "        ap_score.append(average_precision_score(y_test_bin[:, i], y_score[:, i]))\n",
        "\n",
        "    all_precision = np.unique(np.concatenate([precision[i] for i in range(n_classes)]))\n",
        "    mean_recall = np.zeros_like(all_precision)\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        mean_recall += np.interp(all_precision, precision[i][::-1], recall[i][::-1])\n",
        "\n",
        "    mean_recall /= n_classes\n",
        "    macro_ap = np.mean(ap_score)\n",
        "    average_precisions[name] = macro_ap\n",
        "\n",
        "    plt.plot(mean_recall, all_precision, label=f\"{name} (AP = {macro_ap:.4f})\")\n",
        "\n",
        "# Final styling with darker text\n",
        "plt.xlabel(\"Recall\", color='black', fontsize=12)\n",
        "plt.ylabel(\"Precision\", color='black', fontsize=12)\n",
        "plt.title(\"Macro-Average Precision-Recall Curves (After SMOTE)\", color='black', fontsize=14)\n",
        "plt.legend(loc=\"lower left\", fontsize=9, facecolor='white', edgecolor='black')\n",
        "plt.grid(True)\n",
        "plt.tick_params(colors='black')  # Darker tick labels\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qc-19j_N5rOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn xgboost matplotlib\n"
      ],
      "metadata": {
        "id": "q0cRflQY5vmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vhm1FhJyDoHJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}